"""
è¨“ç·´ä¸¦å„²å­˜å„ªåŒ–çš„ Random Forest æ¨¡å‹
é‡å°å°æ•¸æ“šé›†å„ªåŒ–,ä½¿ç”¨å¢å¼·ç‰¹å¾µå·¥ç¨‹
"""
import pandas as pd
import pickle
import os
from sqlalchemy import create_engine
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import accuracy_score, mean_absolute_error, r2_score, classification_report
from datetime import datetime
import config

# å»ºç«‹ models ç›®éŒ„
os.makedirs('models', exist_ok=True)

# Database Connection
db_connection_str = f'mysql+pymysql://{config.DB_USER}:{config.DB_PASSWORD}@{config.DB_HOST}/{config.DB_NAME}'
db_connection = create_engine(db_connection_str)

print("ğŸ“Š è¼‰å…¥å“¡å·¥è³‡æ–™...")
query = """
SELECT 
    e.EmployeeID, e.FirstName, e.LastName,
    e.DateOfBirth, e.HireDate, e.Gender, e.JobTitle,
    d.DepartmentName, s.StatusName,
    sa.BaseSalary, sa.Bonus
FROM Employee e
JOIN Salary sa ON e.EmployeeID = sa.EmployeeID
JOIN Department d ON e.DepartmentID = d.DepartmentID
JOIN Status s ON e.StatusID = s.StatusID;
"""

df = pd.read_sql(query, db_connection)
print(f"âœ… è¼‰å…¥ {len(df)} ç­†å“¡å·¥è³‡æ–™")

# Feature Engineering
current_year = datetime.now().year
df['DateOfBirth'] = pd.to_datetime(df['DateOfBirth'])
df['HireDate'] = pd.to_datetime(df['HireDate'])
df['Age'] = current_year - df['DateOfBirth'].dt.year
df['Tenure'] = current_year - df['HireDate'].dt.year
df['TotalComp'] = df['BaseSalary'] + df['Bonus']

# ============================================
# 1. è¨“ç·´é›¢è·é¢¨éšªé æ¸¬æ¨¡å‹ (Random Forest)
# ============================================
print("\nğŸŒ² è¨“ç·´ Random Forest é›¢è·é¢¨éšªé æ¸¬æ¨¡å‹...")

def calculate_turnover_risk(row):
    """Rule-based turnover risk calculation"""
    if row['StatusName'] in ['Temp', 'Ext']:
        return 'High'
    elif row['Tenure'] < 3:
        if row['TotalComp'] < 40000:
            return 'High'
        else:
            return 'Medium'
    elif row['Tenure'] < 7:
        if row['TotalComp'] < df['TotalComp'].median():
            return 'Medium'
        else:
            return 'Low'
    else:
        if row['TotalComp'] >= df['TotalComp'].quantile(0.4):
            return 'Low'
        else:
            return 'Medium'

df['TurnoverRisk_Actual'] = df.apply(calculate_turnover_risk, axis=1)

# å¢å¼·ç‰¹å¾µå·¥ç¨‹ (ç²¾ç°¡ç‰ˆ - åªä¿ç•™æœ€é‡è¦çš„ç‰¹å¾µ)
print("   ğŸ”§ é€²è¡Œç‰¹å¾µå·¥ç¨‹...")
df['Salary_to_Median_Ratio'] = df['BaseSalary'] / df['BaseSalary'].median()
df['Bonus_to_Salary_Ratio'] = df['Bonus'] / (df['BaseSalary'] + 1)
df['Is_Low_Salary'] = (df['BaseSalary'] < df['BaseSalary'].quantile(0.25)).astype(int)
df['Is_New_Employee'] = (df['Tenure'] < 2).astype(int)
df['Is_Senior'] = (df['Tenure'] >= 7).astype(int)
df['Comp_per_Year'] = df['TotalComp'] / (df['Tenure'] + 1)
df['Risk_Score'] = (
    (df['Is_New_Employee'] * 2) +
    (df['Is_Low_Salary'] * 2) +
    ((df['StatusName'].isin(['Temp', 'Ext'])).astype(int) * 3)
)

# Encode categorical variables
le_gender = LabelEncoder()
le_dept = LabelEncoder()
le_status = LabelEncoder()
le_job = LabelEncoder()
le_risk = LabelEncoder()

df['TurnoverRisk_Encoded'] = le_risk.fit_transform(df['TurnoverRisk_Actual'])

# ç²¾ç°¡ç‰¹å¾µé›† (åªç”¨æœ€é‡è¦çš„)
turnover_features = df[['Age', 'Tenure', 'BaseSalary', 'Bonus', 'TotalComp', 
                         'Gender', 'DepartmentName', 'StatusName',
                         'Salary_to_Median_Ratio', 'Is_Low_Salary',
                         'Is_New_Employee', 'Is_Senior',
                         'Comp_per_Year', 'Risk_Score']].copy()

turnover_features['Gender_Encoded'] = le_gender.fit_transform(turnover_features['Gender'])
turnover_features['Department_Encoded'] = le_dept.fit_transform(turnover_features['DepartmentName'])
turnover_features['Status_Encoded'] = le_status.fit_transform(turnover_features['StatusName'])

X_turnover = turnover_features[['Age', 'Tenure', 'BaseSalary', 'Bonus', 'TotalComp',
                                 'Gender_Encoded', 'Department_Encoded', 'Status_Encoded',
                                 'Salary_to_Median_Ratio', 'Is_Low_Salary',
                                 'Is_New_Employee', 'Is_Senior',
                                 'Comp_per_Year', 'Risk_Score']]
y_turnover = df['TurnoverRisk_Actual']  # Random Forest å¯ä»¥ç›´æ¥ç”¨å­—ä¸²æ¨™ç±¤

# Split data
X_train_t, X_test_t, y_train_t, y_test_t = train_test_split(
    X_turnover, y_turnover, test_size=0.2, random_state=42, stratify=y_turnover
)

# GridSearchCV å°‹æ‰¾æœ€ä½³åƒæ•¸ (é‡å°å°æ•¸æ“šé›†)
print("   ğŸ” å°‹æ‰¾æœ€ä½³ Random Forest åƒæ•¸...")
param_grid = {
    'n_estimators': [100, 150, 200],
    'max_depth': [5, 7, 10, None],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2],
    'max_features': ['sqrt', 'log2']
}

rf_turnover_base = RandomForestClassifier(
    random_state=42,
    class_weight='balanced',
    bootstrap=True
)

grid_search = GridSearchCV(
    rf_turnover_base, 
    param_grid, 
    cv=3,
    scoring='accuracy',
    n_jobs=-1,
    verbose=0
)

grid_search.fit(X_train_t, y_train_t)
rf_turnover = grid_search.best_estimator_

print(f"   âœ… æœ€ä½³åƒæ•¸: {grid_search.best_params_}")
print(f"   ğŸ“Š äº¤å‰é©—è­‰åˆ†æ•¸: {grid_search.best_score_*100:.1f}%")

# Evaluate on test set
y_pred_test = rf_turnover.predict(X_test_t)
turnover_accuracy = accuracy_score(y_test_t, y_pred_test)
print(f"   âœ… æ¸¬è©¦é›†æº–ç¢ºç‡: {turnover_accuracy*100:.1f}%")

# è©³ç´°åˆ†é¡å ±å‘Š
print("\n   ğŸ“‹ åˆ†é¡å ±å‘Š:")
print(classification_report(y_test_t, y_pred_test, zero_division=0))

# ç‰¹å¾µé‡è¦æ€§
feature_importance = rf_turnover.feature_importances_
feature_names = X_turnover.columns
top_features = sorted(zip(feature_names, feature_importance), key=lambda x: x[1], reverse=True)[:5]
print(f"   ğŸ” å‰5é‡è¦ç‰¹å¾µ:")
for name, imp in top_features:
    print(f"      - {name}: {imp:.3f}")

# ============================================
# 2. è¨“ç·´è–ªè³‡é æ¸¬æ¨¡å‹
# ============================================
print("\nğŸ’° è¨“ç·´è–ªè³‡é æ¸¬æ¨¡å‹...")

salary_features = df[['Age', 'Tenure', 'Gender', 'DepartmentName', 'JobTitle']].copy()
salary_features['Gender_Encoded'] = le_gender.transform(salary_features['Gender'])
salary_features['Department_Encoded'] = le_dept.transform(salary_features['DepartmentName'])
salary_features['JobTitle_Encoded'] = le_job.fit_transform(salary_features['JobTitle'])

X_salary = salary_features[['Age', 'Tenure', 'Gender_Encoded', 
                             'Department_Encoded', 'JobTitle_Encoded']]
y_salary = df['BaseSalary']

# Split data
X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(
    X_salary, y_salary, test_size=0.2, random_state=42
)

# Train Random Forest Regressor
rf_salary = RandomForestRegressor(
    n_estimators=150,
    max_depth=10,
    random_state=42,
    min_samples_split=2
)
rf_salary.fit(X_train_s, y_train_s)

# Evaluate
y_pred_test_salary = rf_salary.predict(X_test_s)
salary_mae = mean_absolute_error(y_test_s, y_pred_test_salary)
salary_r2 = r2_score(y_test_s, y_pred_test_salary)
print(f"   âœ… è–ªè³‡é æ¸¬ MAE: ${salary_mae:.2f}")
print(f"   âœ… è–ªè³‡é æ¸¬ RÂ²: {salary_r2:.3f}")

# ============================================
# 3. å„²å­˜æ¨¡å‹å’Œç·¨ç¢¼å™¨
# ============================================
print("\nğŸ’¾ å„²å­˜æ¨¡å‹æª”æ¡ˆ...")

with open('models/turnover_model.pkl', 'wb') as f:
    pickle.dump(rf_turnover, f)
print("   âœ… å·²å„²å­˜: models/turnover_model.pkl")

with open('models/salary_model.pkl', 'wb') as f:
    pickle.dump(rf_salary, f)
print("   âœ… å·²å„²å­˜: models/salary_model.pkl")

encoders = {
    'gender': le_gender,
    'department': le_dept,
    'status': le_status,
    'job': le_job,
    'risk': le_risk
}
with open('models/encoders.pkl', 'wb') as f:
    pickle.dump(encoders, f)
print("   âœ… å·²å„²å­˜: models/encoders.pkl")

metrics = {
    'turnover_accuracy': round(turnover_accuracy * 100, 1),
    'turnover_cv_score': round(grid_search.best_score_ * 100, 1),
    'salary_mae': round(salary_mae, 2),
    'salary_r2': round(salary_r2, 3),
    'trained_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
    'training_samples': len(df),
    'model_type': 'Random Forest (Optimized)',
    'best_params': grid_search.best_params_
}
with open('models/metrics.pkl', 'wb') as f:
    pickle.dump(metrics, f)
print("   âœ… å·²å„²å­˜: models/metrics.pkl")

print("\nğŸ‰ æ¨¡å‹è¨“ç·´å®Œæˆ!")
print(f"ğŸ“ æ¨¡å‹æª”æ¡ˆå·²å„²å­˜è‡³ models/ ç›®éŒ„")
print(f"ğŸ“Š è¨“ç·´æ¨£æœ¬æ•¸: {len(df)}")
print(f"ğŸ¯ é›¢è·é¢¨éšªæº–ç¢ºç‡: {turnover_accuracy*100:.1f}%")
print(f"ğŸŒ² æ¨¡å‹é¡å‹: Random Forest (é‡å°å°æ•¸æ“šé›†å„ªåŒ–)")
